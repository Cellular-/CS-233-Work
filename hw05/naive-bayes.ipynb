{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk as n\n",
    "import itertools as i\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plan\n",
    "Generate a cleaned, munged csv from sentiment.csv using homework 4\n",
    "Split munged data into train/test 90/10\n",
    "Change labels from 0 and 1 to \"pos\" and \"neg\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('clean_munge.csv', delimiter=',', encoding='ISO-8859-1')\n",
    "smoother = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 0 and 1 to pos and neg\n",
    "data[\"polarity_text\"] = data.polarity.apply(lambda p: \"neg\" if p == 0 else \"pos\")\n",
    "data[\"split\"] = data.tweet.apply(lambda t: t.split(\" \"))\n",
    "data[\"no_hashtags\"] = data.lowercase.apply(lambda t: t.replace(\"#\", \"\"))\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "ps.stem('writing')\n",
    "\n",
    "def stem(tweet):\n",
    "    stems = []\n",
    "    \n",
    "    tweet_split = tweet.split(\" \")\n",
    "    \n",
    "    for word in tweet_split:\n",
    "        stems.append(ps.stem(word))\n",
    "        \n",
    "    return stems\n",
    "\n",
    "data[\"stems\"] = data[\"lowercase\"].apply(stem)\n",
    "\n",
    "def no_ht_or_mentions(row):\n",
    "    words = []\n",
    "    \n",
    "    for word in row.tweet.split(\" \"):\n",
    "        if \"#\" in word or \"@\" in word:\n",
    "            pass\n",
    "        else:\n",
    "            words.append(word)\n",
    "    \n",
    "    return \" \".join(words)\n",
    "\n",
    "data[\"no_ht_no_mentions\"] = data.apply(no_ht_or_mentions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14400, 1600)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.1)\n",
    "len(train.index), len(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>all_caps</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>numbers</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>stems</th>\n",
       "      <th>polarity_text</th>\n",
       "      <th>split</th>\n",
       "      <th>no_hashtags</th>\n",
       "      <th>no_ht_no_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>780018</td>\n",
       "      <td>0</td>\n",
       "      <td>@pingiwingi Poor thing   Hope you feel better ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['@pingiwingi']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@pingiwingi poor thing   hope you feel better ...</td>\n",
       "      <td>[@pingiwingi, poor, thing, , , hope, you, feel...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[@pingiwingi, Poor, thing, , , Hope, you, feel...</td>\n",
       "      <td>@pingiwingi poor thing   hope you feel better ...</td>\n",
       "      <td>Poor thing   Hope you feel better soon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1051249</td>\n",
       "      <td>1</td>\n",
       "      <td>#FF one of my new faves cos y'all know how I a...</td>\n",
       "      <td>['FF']</td>\n",
       "      <td>['#FF']</td>\n",
       "      <td>['@NuttyNewswire']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#ff one of my new faves cos y'all know how i a...</td>\n",
       "      <td>[#ff, one, of, my, new, fave, co, y'all, know,...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[#FF, one, of, my, new, faves, cos, y'all, kno...</td>\n",
       "      <td>ff one of my new faves cos y'all know how i am...</td>\n",
       "      <td>one of my new faves cos y'all know how I am!  -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54916</td>\n",
       "      <td>0</td>\n",
       "      <td>last day of #tourdeblono before i leave on the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['#tourdeblono']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>last day of #tourdeblono before i leave on the...</td>\n",
       "      <td>[last, day, of, #tourdeblono, befor, i, leav, ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[last, day, of, #tourdeblono, before, i, leave...</td>\n",
       "      <td>last day of tourdeblono before i leave on the ...</td>\n",
       "      <td>last day of before i leave on the greyhound at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>845262</td>\n",
       "      <td>1</td>\n",
       "      <td>hands up if you love the sum on a Monday morni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hands up if you love the sum on a monday morni...</td>\n",
       "      <td>[hand, up, if, you, love, the, sum, on, a, mon...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[hands, up, if, you, love, the, sum, on, a, Mo...</td>\n",
       "      <td>hands up if you love the sum on a monday morni...</td>\n",
       "      <td>hands up if you love the sum on a Monday morni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1066937</td>\n",
       "      <td>1</td>\n",
       "      <td>@nuthatchgirl Hi Stacie, I just sent you a mes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['@nuthatchgirl']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@nuthatchgirl hi stacie, i just sent you a mes...</td>\n",
       "      <td>[@nuthatchgirl, hi, stacie,, i, just, sent, yo...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[@nuthatchgirl, Hi, Stacie,, I, just, sent, yo...</td>\n",
       "      <td>@nuthatchgirl hi stacie, i just sent you a mes...</td>\n",
       "      <td>Hi Stacie, I just sent you a message on Etsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>763700</td>\n",
       "      <td>0</td>\n",
       "      <td>@liamlager i did have an interest in it before...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['@liamlager']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@liamlager i did have an interest in it before...</td>\n",
       "      <td>[@liamlag, i, did, have, an, interest, in, it,...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[@liamlager, i, did, have, an, interest, in, i...</td>\n",
       "      <td>@liamlager i did have an interest in it before...</td>\n",
       "      <td>i did have an interest in it before i saw it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>1137306</td>\n",
       "      <td>1</td>\n",
       "      <td>There's nothing in the world that mommy's kiss...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there's nothing in the world that mommy's kiss...</td>\n",
       "      <td>[there', noth, in, the, world, that, mommy', k...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[There's, nothing, in, the, world, that, mommy...</td>\n",
       "      <td>there's nothing in the world that mommy's kiss...</td>\n",
       "      <td>There's nothing in the world that mommy's kiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>856219</td>\n",
       "      <td>1</td>\n",
       "      <td>@Acousticore though we're gonna see it tomorro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['@Acousticore']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['3']</td>\n",
       "      <td>@acousticore though we're gonna see it tomorro...</td>\n",
       "      <td>[@acousticor, though, we'r, gonna, see, it, to...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[@Acousticore, though, we're, gonna, see, it, ...</td>\n",
       "      <td>@acousticore though we're gonna see it tomorro...</td>\n",
       "      <td>though we're gonna see it tomorrow i guess - o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>1172092</td>\n",
       "      <td>1</td>\n",
       "      <td>Professor said &amp;quot;you could have knocked me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['2009']</td>\n",
       "      <td>professor said &amp;quot;you could have knocked me...</td>\n",
       "      <td>[professor, said, &amp;quot;you, could, have, knoc...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[Professor, said, &amp;quot;you, could, have, knoc...</td>\n",
       "      <td>professor said &amp;quot;you could have knocked me...</td>\n",
       "      <td>Professor said &amp;quot;you could have knocked me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>699272</td>\n",
       "      <td>0</td>\n",
       "      <td>@Julie_oh Ony's really lonely though  She hasn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['@Julie_oh']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@julie_oh ony's really lonely though  she hasn...</td>\n",
       "      <td>[@julie_oh, ony', realli, lone, though, , she,...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[@Julie_oh, Ony's, really, lonely, though, , S...</td>\n",
       "      <td>@julie_oh ony's really lonely though  she hasn...</td>\n",
       "      <td>Ony's really lonely though  She hasn't stopped...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  polarity  \\\n",
       "0          780018         0   \n",
       "1         1051249         1   \n",
       "2           54916         0   \n",
       "3          845262         1   \n",
       "4         1066937         1   \n",
       "...           ...       ...   \n",
       "15995      763700         0   \n",
       "15996     1137306         1   \n",
       "15997      856219         1   \n",
       "15998     1172092         1   \n",
       "15999      699272         0   \n",
       "\n",
       "                                                   tweet all_caps  \\\n",
       "0      @pingiwingi Poor thing   Hope you feel better ...      NaN   \n",
       "1      #FF one of my new faves cos y'all know how I a...   ['FF']   \n",
       "2      last day of #tourdeblono before i leave on the...      NaN   \n",
       "3      hands up if you love the sum on a Monday morni...      NaN   \n",
       "4      @nuthatchgirl Hi Stacie, I just sent you a mes...      NaN   \n",
       "...                                                  ...      ...   \n",
       "15995  @liamlager i did have an interest in it before...      NaN   \n",
       "15996  There's nothing in the world that mommy's kiss...      NaN   \n",
       "15997  @Acousticore though we're gonna see it tomorro...      NaN   \n",
       "15998  Professor said &quot;you could have knocked me...      NaN   \n",
       "15999  @Julie_oh Ony's really lonely though  She hasn...      NaN   \n",
       "\n",
       "               hashtags            mentions urls   numbers  \\\n",
       "0                   NaN     ['@pingiwingi']  NaN       NaN   \n",
       "1               ['#FF']  ['@NuttyNewswire']  NaN       NaN   \n",
       "2      ['#tourdeblono']                 NaN  NaN       NaN   \n",
       "3                   NaN                 NaN  NaN       NaN   \n",
       "4                   NaN   ['@nuthatchgirl']  NaN       NaN   \n",
       "...                 ...                 ...  ...       ...   \n",
       "15995               NaN      ['@liamlager']  NaN       NaN   \n",
       "15996               NaN                 NaN  NaN       NaN   \n",
       "15997               NaN    ['@Acousticore']  NaN     ['3']   \n",
       "15998               NaN                 NaN  NaN  ['2009']   \n",
       "15999               NaN       ['@Julie_oh']  NaN       NaN   \n",
       "\n",
       "                                               lowercase  \\\n",
       "0      @pingiwingi poor thing   hope you feel better ...   \n",
       "1      #ff one of my new faves cos y'all know how i a...   \n",
       "2      last day of #tourdeblono before i leave on the...   \n",
       "3      hands up if you love the sum on a monday morni...   \n",
       "4      @nuthatchgirl hi stacie, i just sent you a mes...   \n",
       "...                                                  ...   \n",
       "15995  @liamlager i did have an interest in it before...   \n",
       "15996  there's nothing in the world that mommy's kiss...   \n",
       "15997  @acousticore though we're gonna see it tomorro...   \n",
       "15998  professor said &quot;you could have knocked me...   \n",
       "15999  @julie_oh ony's really lonely though  she hasn...   \n",
       "\n",
       "                                                   stems polarity_text  \\\n",
       "0      [@pingiwingi, poor, thing, , , hope, you, feel...           neg   \n",
       "1      [#ff, one, of, my, new, fave, co, y'all, know,...           pos   \n",
       "2      [last, day, of, #tourdeblono, befor, i, leav, ...           neg   \n",
       "3      [hand, up, if, you, love, the, sum, on, a, mon...           pos   \n",
       "4      [@nuthatchgirl, hi, stacie,, i, just, sent, yo...           pos   \n",
       "...                                                  ...           ...   \n",
       "15995  [@liamlag, i, did, have, an, interest, in, it,...           neg   \n",
       "15996  [there', noth, in, the, world, that, mommy', k...           pos   \n",
       "15997  [@acousticor, though, we'r, gonna, see, it, to...           pos   \n",
       "15998  [professor, said, &quot;you, could, have, knoc...           pos   \n",
       "15999  [@julie_oh, ony', realli, lone, though, , she,...           neg   \n",
       "\n",
       "                                                   split  \\\n",
       "0      [@pingiwingi, Poor, thing, , , Hope, you, feel...   \n",
       "1      [#FF, one, of, my, new, faves, cos, y'all, kno...   \n",
       "2      [last, day, of, #tourdeblono, before, i, leave...   \n",
       "3      [hands, up, if, you, love, the, sum, on, a, Mo...   \n",
       "4      [@nuthatchgirl, Hi, Stacie,, I, just, sent, yo...   \n",
       "...                                                  ...   \n",
       "15995  [@liamlager, i, did, have, an, interest, in, i...   \n",
       "15996  [There's, nothing, in, the, world, that, mommy...   \n",
       "15997  [@Acousticore, though, we're, gonna, see, it, ...   \n",
       "15998  [Professor, said, &quot;you, could, have, knoc...   \n",
       "15999  [@Julie_oh, Ony's, really, lonely, though, , S...   \n",
       "\n",
       "                                             no_hashtags  \\\n",
       "0      @pingiwingi poor thing   hope you feel better ...   \n",
       "1      ff one of my new faves cos y'all know how i am...   \n",
       "2      last day of tourdeblono before i leave on the ...   \n",
       "3      hands up if you love the sum on a monday morni...   \n",
       "4      @nuthatchgirl hi stacie, i just sent you a mes...   \n",
       "...                                                  ...   \n",
       "15995  @liamlager i did have an interest in it before...   \n",
       "15996  there's nothing in the world that mommy's kiss...   \n",
       "15997  @acousticore though we're gonna see it tomorro...   \n",
       "15998  professor said &quot;you could have knocked me...   \n",
       "15999  @julie_oh ony's really lonely though  she hasn...   \n",
       "\n",
       "                                       no_ht_no_mentions  \n",
       "0                Poor thing   Hope you feel better soon.  \n",
       "1        one of my new faves cos y'all know how I am!  -  \n",
       "2      last day of before i leave on the greyhound at...  \n",
       "3      hands up if you love the sum on a Monday morni...  \n",
       "4          Hi Stacie, I just sent you a message on Etsy   \n",
       "...                                                  ...  \n",
       "15995  i did have an interest in it before i saw it, ...  \n",
       "15996  There's nothing in the world that mommy's kiss...  \n",
       "15997  though we're gonna see it tomorrow i guess - o...  \n",
       "15998  Professor said &quot;you could have knocked me...  \n",
       "15999  Ony's really lonely though  She hasn't stopped...  \n",
       "\n",
       "[16000 rows x 14 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate P(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter as ctr\n",
    "\n",
    "p_t_estimate = ctr(train.polarity_text)\n",
    "p_t_total = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7196, 7204)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_t_estimate['neg'], p_t_estimate['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pt(T):\n",
    "    return p_t_estimate[T] / p_t_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49972222222222223, 0.5002777777777778)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pt('neg'), Pt('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate P(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_words = [w for s in train.split for w in s]\n",
    "p_w_estimate = ctr(tweet_words)\n",
    "p_w_total = len(tweet_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pw(W):\n",
    "    if W not in p_w_estimate: return smoother\n",
    "    return p_w_estimate[W] / p_w_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021387202399610353"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pw('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([Pw(w) for w in set(tweet_words)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate P(W|T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_w_t_estimate = {}\n",
    "p_w_t_totals = {}\n",
    "\n",
    "for t in set(train.polarity_text):\n",
    "    sub_frame = train[train.polarity_text == t]\n",
    "    sub_words = [w for s in sub_frame.split for w in s]\n",
    "    p_w_t_estimate[t] = ctr(sub_words)\n",
    "    p_w_t_totals[t] = len(sub_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pwt(W, T):\n",
    "    if W not in p_w_t_estimate[T]: return smoother\n",
    "    return p_w_t_estimate[T][W] / p_w_t_totals[T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ptw(T, W):\n",
    "    return Pwt(W, T) * Pt(T) / Pw(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pe(E):\n",
    "    result = {}\n",
    "    for t in set(train.polarity_text):\n",
    "        result[t] = np.prod([Ptw(t, word) for word in E])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'pos': 0.00342866987624089, 'neg': 0.20868887176710693},\n",
       " {'pos': 0.00258572388856779, 'neg': 0.24149146202558178})"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pe(\"today has been horrible\".split(\" \")), Pe(\"Today has been horrible\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steven\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\steven\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76125"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(df, col):\n",
    "    results_col = col + \"_result\"\n",
    "    top_col = col + \"_top\"\n",
    "    df[results_col] = df[col].apply(Pe)\n",
    "    df[top_col] = df[results_col].apply(lambda x: max(x, key=x.get))\n",
    "    return sum(df.polarity_text == df[top_col]) / len(df)\n",
    "\n",
    "score(df=test, col=\"split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steven\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\steven\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.469375"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(df=test, col=\"lowercase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steven\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\steven\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.469375"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(df=test, col=\"no_hashtags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steven\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\steven\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.734375"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(df=test, col=\"stems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open ended approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steven\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\steven\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.478125"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "I am going to remove all hashtag words and mentions from each tweet.\n",
    "Then, run the classifier on the new tweets and get a score.\n",
    "\"\"\"\n",
    "\n",
    "score(df=test, col=\"no_ht_no_mentions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline:\n",
    "    \n",
    "    The types of tweets, negative or positive, were evenly probable at about 50% each.\n",
    "\n",
    "Classifier accuracy of split text:\n",
    "    \n",
    "    .76\n",
    "    \n",
    "Classifier accuracy of lower-cased, split text\n",
    "    \n",
    "    .47\n",
    "    \n",
    "Classifier accuracy of the lower-cased, split text with hashtag symbols removed\n",
    "\n",
    "    .47\n",
    "    \n",
    "Classifier accuracy of lower-cased, split text with stemmed words\n",
    "\n",
    "    .73\n",
    "    \n",
    "Open ended approach classifier accuracy\n",
    "    \n",
    "    .48\n",
    "    \n",
    "    My hypothesis was that hashtags and mentions are mostly \"white noise\" in the tweets.\n",
    "    Hashtags and mentions can be evenly used for both negative and positive tweets which is why I opted to remove them.\n",
    "    But my classifier accuracy on those tweets in the lowest of all classifier accuracies. \n",
    "    This leads me to believe that hashtags and/or mentions carry a significant sentiment value and should not be\n",
    "    disregarded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
