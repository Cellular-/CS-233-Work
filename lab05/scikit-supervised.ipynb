{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _olivetti_faces_dataset:\n",
      "\n",
      "The Olivetti faces dataset\n",
      "--------------------------\n",
      "\n",
      "`This dataset contains a set of face images`_ taken between April 1992 and \n",
      "April 1994 at AT&T Laboratories Cambridge. The\n",
      ":func:`sklearn.datasets.fetch_olivetti_faces` function is the data\n",
      "fetching / caching function that downloads the data\n",
      "archive from AT&T.\n",
      "\n",
      ".. _This dataset contains a set of face images: http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\n",
      "\n",
      "As described on the original website:\n",
      "\n",
      "    There are ten different images of each of 40 distinct subjects. For some\n",
      "    subjects, the images were taken at different times, varying the lighting,\n",
      "    facial expressions (open / closed eyes, smiling / not smiling) and facial\n",
      "    details (glasses / no glasses). All the images were taken against a dark\n",
      "    homogeneous background with the subjects in an upright, frontal position \n",
      "    (with tolerance for some side movement).\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   =====================\n",
      "    Classes                                40\n",
      "    Samples total                         400\n",
      "    Dimensionality                       4096\n",
      "    Features            real, between 0 and 1\n",
      "    =================   =====================\n",
      "\n",
      "The image is quantized to 256 grey levels and stored as unsigned 8-bit \n",
      "integers; the loader will convert these to floating point values on the \n",
      "interval [0, 1], which are easier to work with for many algorithms.\n",
      "\n",
      "The \"target\" for this database is an integer from 0 to 39 indicating the\n",
      "identity of the person pictured; however, with only 10 examples per class, this\n",
      "relatively small dataset is more interesting from an unsupervised or\n",
      "semi-supervised perspective.\n",
      "\n",
      "The original dataset consisted of 92 x 112, while the version available here\n",
      "consists of 64x64 images.\n",
      "\n",
      "When using these images, please give credit to AT&T Laboratories Cambridge.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = datasets.fetch_olivetti_faces()\n",
    "\n",
    "print(data[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.442149</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665289</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.652893</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.157025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.491736</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.698347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.128099</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.140496</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198347</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>0.516529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652893</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.739669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.582645</td>\n",
       "      <td>0.623967</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.694215</td>\n",
       "      <td>0.714876</td>\n",
       "      <td>0.723140</td>\n",
       "      <td>0.731405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.173554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.309917  0.367769  0.417355  0.442149  0.528926  0.607438  0.657025   \n",
       "1  0.454545  0.471074  0.512397  0.557851  0.595041  0.640496  0.681818   \n",
       "2  0.318182  0.400826  0.491736  0.528926  0.586777  0.657025  0.681818   \n",
       "3  0.198347  0.194215  0.194215  0.194215  0.190083  0.190083  0.243802   \n",
       "4  0.500000  0.545455  0.582645  0.623967  0.648760  0.690083  0.694215   \n",
       "\n",
       "       7         8         9     ...      4086      4087      4088      4089  \\\n",
       "0  0.677686  0.690083  0.685950  ...  0.665289  0.669421  0.652893  0.661157   \n",
       "1  0.702479  0.710744  0.702479  ...  0.136364  0.157025  0.136364  0.148760   \n",
       "2  0.685950  0.702479  0.698347  ...  0.074380  0.132231  0.181818  0.136364   \n",
       "3  0.404959  0.483471  0.516529  ...  0.652893  0.636364  0.657025  0.685950   \n",
       "4  0.714876  0.723140  0.731405  ...  0.190083  0.161157  0.177686  0.173554   \n",
       "\n",
       "       4090      4091      4092      4093      4094      4095  \n",
       "0  0.475207  0.132231  0.148760  0.152893  0.161157  0.157025  \n",
       "1  0.152893  0.152893  0.152893  0.152893  0.152893  0.152893  \n",
       "2  0.128099  0.148760  0.144628  0.140496  0.148760  0.152893  \n",
       "3  0.727273  0.743802  0.764463  0.752066  0.752066  0.739669  \n",
       "4  0.177686  0.177686  0.177686  0.177686  0.173554  0.173554  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_data = pd.DataFrame(data[\"data\"])\n",
    "face_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.442149</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.652893</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.491736</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.698347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.128099</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.140496</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198347</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>0.516529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.739669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.582645</td>\n",
       "      <td>0.623967</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.694215</td>\n",
       "      <td>0.714876</td>\n",
       "      <td>0.723140</td>\n",
       "      <td>0.731405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.309917  0.367769  0.417355  0.442149  0.528926  0.607438  0.657025   \n",
       "1  0.454545  0.471074  0.512397  0.557851  0.595041  0.640496  0.681818   \n",
       "2  0.318182  0.400826  0.491736  0.528926  0.586777  0.657025  0.681818   \n",
       "3  0.198347  0.194215  0.194215  0.194215  0.190083  0.190083  0.243802   \n",
       "4  0.500000  0.545455  0.582645  0.623967  0.648760  0.690083  0.694215   \n",
       "\n",
       "          7         8         9  ...      4087      4088      4089      4090  \\\n",
       "0  0.677686  0.690083  0.685950  ...  0.669421  0.652893  0.661157  0.475207   \n",
       "1  0.702479  0.710744  0.702479  ...  0.157025  0.136364  0.148760  0.152893   \n",
       "2  0.685950  0.702479  0.698347  ...  0.132231  0.181818  0.136364  0.128099   \n",
       "3  0.404959  0.483471  0.516529  ...  0.636364  0.657025  0.685950  0.727273   \n",
       "4  0.714876  0.723140  0.731405  ...  0.161157  0.177686  0.173554  0.177686   \n",
       "\n",
       "       4091      4092      4093      4094      4095  y  \n",
       "0  0.132231  0.148760  0.152893  0.161157  0.157025  0  \n",
       "1  0.152893  0.152893  0.152893  0.152893  0.152893  0  \n",
       "2  0.148760  0.144628  0.140496  0.148760  0.152893  0  \n",
       "3  0.743802  0.764463  0.752066  0.752066  0.739669  0  \n",
       "4  0.177686  0.177686  0.177686  0.173554  0.173554  0  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_data[\"y\"] = data[\"target\"]\n",
    "face_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 40)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(face_data, test_size=0.1)\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(max_iter=10000)\n",
    "\n",
    "cols = np.arange(0, 4096)\n",
    "X = train[cols].values\n",
    "y = train.y.values\n",
    "X_test = test[cols].values\n",
    "y_test = test.y.values\n",
    "\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "dt.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_cl = svm.SVC()\n",
    "svm_cl.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the features?\n",
    "    \n",
    "    The features are the 4096 points that make up a picture of a given person.\n",
    "\n",
    "What was it your classifier was trying to classify? (Hint: You'll need to read the description of the data--this constitutes the classification \"task\"; i.e., the mapping from features in X to the classification labels in y)\n",
    "\n",
    "    It was trying to classify a set of points that make up a picture to the person in the picture.\n",
    "    \n",
    "What is the baseline for this dataset? (Hint: what is the most common type that could be classified?)\n",
    "\n",
    "    10% because each class was distributed evenly.   \n",
    "    \n",
    "How well did your three classifiers do above the baseline.\n",
    "\n",
    "    The logistic regression classifier and support vector machine did very well, but the decision tree performed poorly in comparison.\n",
    "    \n",
    "\n",
    "Read a little bit about each classifier. Why do you think one classifier did better than another classifier?\n",
    "\n",
    "    Logistic regression had the highest score, support vector machine had the 2nd highest score and decision\n",
    "    trees had the worst score.\n",
    "    \n",
    "    Decision trees are prone to overfitting and can generate entirely different trees with minor changes in\n",
    "    the data. If an ensemble of decision trees were used, then perhaps the classification score would improve.\n",
    "    \n",
    "    Support vector machine classifier performed well. This may be because svms are effective in high dimensional\n",
    "    spaces. In the case of train/test data, there were 4096 dimensions, over 10 times the original sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open ended exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the input features?\n",
    "\n",
    "    Real-valued feature vectors.\n",
    "    \n",
    "What are the class labels?\n",
    "\n",
    "    Positive class or negative class for binary classification.\n",
    "\n",
    "How is the data represented?\n",
    "\n",
    "    In matrices\n",
    "\n",
    "Do you think any of the three classification approaches you used for the Olivettie Faces above would work for this task?\n",
    "\n",
    "    Support vector machines might be good for this since in a recommendation engine you might have access to a lot of features of the user (high dimensionsiality.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the input features?\n",
    "\n",
    "    Countries, their continents and their neighboring countries (Knowledge graphs).\n",
    "    \n",
    "What are the class labels?\n",
    "\n",
    "    Missing graph link or not\n",
    "\n",
    "How is the data represented?\n",
    "\n",
    "    In tab separated triples of a knowledge graph.\n",
    "\n",
    "Do you think any of the three classification approaches you used for the Olivettie Faces above would work for this task?\n",
    "\n",
    "    Logistic regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
